#!/usr/bin/env python

"""
- Uses Edit distances per word of every translation and chooses the one which is closes to every other
translation as the best one 
- Outputs the sentence with the best average Levenshtein distance with its fellow translations.
- Here we used words as entities rather than characters in the string while calculating Levenshtein distance.

## BLEU score : 0.29
"""

import optparse
from numpy import argmin,mean
from nltk import word_tokenize;

optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/turk_translations.tsv", help="MTurk translations file")
opts = optparser.parse_args()[0]


'''
The following code of Levenshtein distance is taken from
http://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance
Minor modifcations are made to the code
'''
def levenshteinDistance(s1,s2):
    s1 = word_tokenize(s1) ;
    s2 = word_tokenize(s2) ;
    if len(s1) > len(s2):
        s1,s2 = s2,s1
    distances = range(len(s1) + 1)
    for index2,char2 in enumerate(s2):
        newDistances = [index2+1]
        for index1,char1 in enumerate(s1):
            if char1 == char2:
                newDistances.append(distances[index1])
            else:
                newDistances.append(1 + min((distances[index1],
                                             distances[index1+1],
                                             newDistances[-1])))
        distances = newDistances
    return distances[-1]


all_hyps = [line.split('\t')[1:] for line in open(opts.input)]
for (ind,hyp) in enumerate(all_hyps[1:]) :
    sents = hyp[0:4];
    dis = [];
    for (ind,sent) in enumerate(sents) :
         dis.append(mean([ levenshteinDistance(s,sent) for s in sents ]));
    min_ind = argmin( dis );  
    print sents[min_ind];
